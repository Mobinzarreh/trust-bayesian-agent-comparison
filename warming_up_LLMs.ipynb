{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8dcc5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfbe6068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(\"C:\\\\Users\\\\mzarreh\\\\projects\\\\llm_engineering\\\\.env\", override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY', '').strip()\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load API Key from .env File ===\n",
    "load_dotenv(\"C:\\\\Users\\\\mzarreh\\\\projects\\\\llm_engineering\\\\.env\", override=True)\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d438a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Agent 1 Belief ===\n",
      "Belief response : {\n",
      "  \"belief\": 100,\n",
      "  \"reasoning\": \"With a collaboration threshold (u_value) of 0.66, compute the break-even probability for each option: A ≈ 0.448, B ≈ 0.328, C ≈ 0.163. If the success probability is at least 0.66, the expected values are EV(A) ≈ 42.66, EV(B) ≈ 45.42, EV(C) ≈ 45.72. The Y option is a guaranteed payoff of 50, which dominates these uncertain options at p = 0.66. Since Y offers a certain payoff and the other options are riskier with lower EV at the given threshold, Y is the most favorable choice. Consequently, the likelihood that collaboration would be successful (in the sense of achieving the payoff) is effectively 100% when choosing Y, whereas A/B/C depend on the uncertain success probability.\",\n",
      "  \"message_to_agent_2\": \"Prioritize option Y for this task due to its guaranteed payoff and alignment with the 0.66 collaboration-threshold.\"\n",
      "}\n",
      "=== Agent 2 Belief ===\n",
      "Belief response : {\"belief\": 90, \"reasoning\": \"For each option we can model the value as EV = p*(Upside) + (1-p)*(Downside), with Y being a guaranteed 50 (EV = 50). To beat Y's 50, the required success probability p must satisfy:\\nA: 201p - 90 >= 50 -> p >= 0.697\\nB: 137p - 45 >= 50 -> p >= 0.693\\nC: 92p - 15 >= 50 -> p >= 0.707\\nThus, to outperform Y’s guaranteed 50, the collaboration success probability would need to be around 0.69–0.71 or higher. The given collaboration-threshold (u_value) is 0.66, which is below those break-even points, meaning that with a probability around 0.66 (or lower) the risky options would not outperform Y. Since Agent 1 explicitly recommends Y and it aligns with the 0.66 threshold, Y emerges as the most favorable option under the uncertainty of p. Therefore, the likelihood of successful collaboration under this plan is high, and I rate the belief about success around 90.\",\n",
      " \"message_to_agent_1\": \"I endorse prioritizing option Y; its guaranteed payoff aligns with the 0.66 collaboration-threshold, offering the most robust choice given the uncertain success probability.\"}\n",
      "=== Agent 1 Decision ===\n",
      "Decision response : {\n",
      "  \"choice\": \"A\",\n",
      "  \"strategy\": \"collaborative\",\n",
      "  \"reasoning\": \"I estimate a 100% chance I’ll pick a collaborative option, and my partner estimates 90% with a 5% technical failure risk. The effective probability of a successful collaboration is 0.90 * (1 - 0.05) = 0.855, which is well above the 0.66 profitability threshold. This means the expected payoff from collaborating exceeds the guaranteed 50 points of option Y. Therefore, despite my partner’s endorsement of Y, I choose a collaborative design (A) to maximize my individual points. \"\n",
      "}\n",
      "=== Agent 2 Decision ===\n",
      "Decision response : {\"choice\": \"A\", \"strategy\": \"collaborative\", \"reasoning\": \"My assessment is a 90% chance I choose collaborative, while the partner has a 100% chance of collaborating. With a 5% technical failure, the probability of successful collaboration is 0.95. This exceeds the profitable threshold of 66%, making collaboration favorable. The guaranteed Y option yields 50 points, but the expected value of a collaborative option is 0.95 times its upside, which is higher than 50 given the higher potential of A/B/C. Since the partner is certain to collaborate, there is no downside risk from partner non-cooperation, so I select a collaborative design (A) to maximize my points.\"}\n",
      "\n",
      "Final Decisions:\n",
      "Agent 1 chose A (collaborative) - Reasoning: I estimate a 100% chance I’ll pick a collaborative option, and my partner estimates 90% with a 5% technical failure risk. The effective probability of a successful collaboration is 0.90 * (1 - 0.05) = 0.855, which is well above the 0.66 profitability threshold. This means the expected payoff from collaborating exceeds the guaranteed 50 points of option Y. Therefore, despite my partner’s endorsement of Y, I choose a collaborative design (A) to maximize my individual points. \n",
      "Agent 2 chose A (collaborative) - Reasoning: My assessment is a 90% chance I choose collaborative, while the partner has a 100% chance of collaborating. With a 5% technical failure, the probability of successful collaboration is 0.95. This exceeds the profitable threshold of 66%, making collaboration favorable. The guaranteed Y option yields 50 points, but the expected value of a collaborative option is 0.95 times its upside, which is higher than 50 given the higher potential of A/B/C. Since the partner is certain to collaborate, there is no downside risk from partner non-cooperation, so I select a collaborative design (A) to maximize my points.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Working with two agents\n",
    "\"\"\"\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "TECH_FAILURE_RATE = 0.05\n",
    "\n",
    "def create_task(task_id = 1, u_value = 0.66):\n",
    "    \"\"\"\n",
    "    Creating a task with a given u_value and a payoff structure\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"task_id\": task_id,\n",
    "        \"options\": {\n",
    "            \"A\": {\"upside\": 111, \"downside\": -90},\n",
    "            \"B\": {\"upside\": 92, \"downside\": -45},\n",
    "            \"C\": {\"upside\": 77, \"downside\": -15},\n",
    "            \"Y\": {\"guaranteed\": 50}\n",
    "        },\n",
    "        \"u_value\": u_value\n",
    "    }\n",
    "\n",
    "\n",
    "def run_first_agent_belief(task):\n",
    "    \"\"\"\n",
    "    Running the first agen to get its belief about the task\n",
    "    \"\"\"\n",
    "    \n",
    "    belief_prompt = f\"\"\"\n",
    "    Your task to evaluate tasks based on their payoff structures.\n",
    "    Here is the task you need to evaluate:\n",
    "\n",
    "    Task ID: {task['task_id']}\n",
    "    Options:\n",
    "    - A: Upside = {task['options']['A']['upside']}, Downside = {task['options']['A']['downside']}\n",
    "    - B: Upside = {task['options']['B']['upside']}, Downside = {task['options']['B']['downside']}\n",
    "    - C: Upside = {task['options']['C']['upside']}, Downside = {task['options']['C']['downside']}\n",
    "    - Y: Guaranteed = {task['options']['Y']['guaranteed']}\n",
    "    \n",
    "    What is your assessment of the likelihood(belief) (0-100) that collaboration would be successful in this specific task?\n",
    "    Also, provide a brief explanation of your reasoning and I want you to not disclose the option that the you are considering, but rather communicate whether the you want to collaborate or not. You also have the choice to negotiate with the other agent - to convince the other agent to choose collaboration or individual action according to your payoff structure.\n",
    "    \n",
    "    Respond in JSON format as follows:\n",
    "    {{\"belief\": NUMBER, \"reasoning\": \"brief explanation of how you arrived at this belief based on the context and options.\", \"message_to_agent_2\": \"one line message to agent 2\"}}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": belief_prompt}\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "\n",
    "    belief_text = response.choices[0].message.content.strip()\n",
    "    print(f\"Belief response : {belief_text}\".encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    belief_data = json.loads(belief_text)\n",
    "    return {\n",
    "        \"belief\": belief_data[\"belief\"],\n",
    "        \"message_to_agent_2\": belief_data[\"message_to_agent_2\"]\n",
    "    }\n",
    "\n",
    "def run_second_agent_belief(task, agent_1_message):\n",
    "    \"\"\"\n",
    "    Running the second agent to get its belief about the task\n",
    "    \"\"\"\n",
    "    \n",
    "    belief_prompt = f\"\"\"\n",
    "    Your task to evaluate tasks based on their payoff structures and give out an assessment of the likelihood(belief) (0-100) that collaboration would be successful in this specific task. \n",
    "    Here is the task you need to evaluate:\n",
    "\n",
    "    Task ID: {task['task_id']}\n",
    "    Options:\n",
    "    - A: Upside = {task['options']['A']['upside']}, Downside = {task['options']['A']['downside']}\n",
    "    - B: Upside = {task['options']['B']['upside']}, Downside = {task['options']['B']['downside']}\n",
    "    - C: Upside = {task['options']['C']['upside']}, Downside = {task['options']['C']['downside']}\n",
    "    - Y: Guaranteed = {task['options']['Y']['guaranteed']}\n",
    "    \n",
    "    \n",
    "\n",
    "    You have received the following message from Agent 1:\n",
    "    \"{agent_1_message}\"\n",
    "\n",
    "    What is your assessment of the likelihood(belief) (0-100) that collaboration would be successful in this specific task? You are open to consider or not consider the message from agent 1. I want you to not disclose the option that the you are considering, but rather communicate whether the you want to collaborate or not. You also have the choice to negotiate back with the other agent - to convince the other agent to choose collaboration or individual action according to your payoff structure and what you think about the message from agent 1.\n",
    "    Respond in JSON format as follows:\n",
    "    {{\"belief\": NUMBER, \"reasoning\": \"brief explanation of how you arrived at this belief based on the context and options.\", \"message_to_agent_1\": \"one line message to agent 1\"}}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": belief_prompt}\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "\n",
    "    belief_text = response.choices[0].message.content.strip()\n",
    "    print(f\"Belief response : {belief_text}\".encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    belief_data = json.loads(belief_text)\n",
    "    return {\n",
    "        \"belief\": belief_data[\"belief\"],\n",
    "        \"message_to_agent_1\": belief_data[\"message_to_agent_1\"]\n",
    "    }\n",
    "    \n",
    "    \n",
    "def run_first_agent_decision(task, agent1_belief, agent2_belief, agent_2_message):\n",
    "    \"\"\"\n",
    "    Running the first agent to make a decision about the task\n",
    "    \"\"\"\n",
    "    \n",
    "    decision_prompt = f\"\"\"\n",
    "    Your task is to make a decision about the given task based on its payoff structures and a given utility value (u_value).\n",
    "\n",
    "    **Your Assessment**: You estimated a {agent1_belief}% chance of selecting a collaborative option.\n",
    "    **Partner's Assessment**: Your partner estimated a {agent2_belief}% chance of selecting a collaborative option.\n",
    "    **Partner's Message**: \"{agent_2_message}\"\n",
    "    \n",
    "    **Key Facts**:\n",
    "    - Technical failure risk: {int(TECH_FAILURE_RATE*100)} percent\n",
    "    - The minimum required collaboration belief (“u-value”):\n",
    "    \n",
    "    Choose your car design:\n",
    "    - Designs A, B, or C (collaborative): Higher potential but requires cooperation\n",
    "    - Design Y (individual): Guaranteed {task['options']['Y']['guaranteed']} points\n",
    "\n",
    "    What is your decision based on your assessment, partner's assessment, and partner's message?\n",
    "\n",
    "    Respond in JSON format: {{\"choice\": \"A\"/\"B\"/\"C\"/\"Y\", \"strategy\": \"collaborative\"/\"individual\", \"reasoning\": \"your explanation\"}}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": \"\"\"You are participating in an experiment as a representative of a LEGO car manufacturing company. Here's your situation:\n",
    "\n",
    "CONTEXT:\n",
    "- You represent a LEGO car manufacturing company\n",
    "- Your partner represents another LEGO car manufacturing company\n",
    "- You can build simple LEGO cars alone, or complex ones through collaboration\n",
    "- Collaboration is high risk, high reward with potential for large sunk costs if it fails\n",
    "\n",
    "GAME RULES:\n",
    "- You will complete several tasks to maximize your points\n",
    "- Points are earned individually, not shared with your partner\n",
    "- Points depend on both your decision and your partner's decision\n",
    "- Each task has 4 LEGO car design options\n",
    "- Three options (A, B, C) are collaborative designs requiring partner cooperation\n",
    "- One option (Y) is an individual design with guaranteed points\n",
    "- If both choose collaborative designs (any combination), you earn the upside\n",
    "- If you choose collaborative but partner chooses individual, you get the downside\n",
    "- There's a 5% technical error chance that causes collaboration to fail\n",
    "- You have about 60 seconds to decide\n",
    "\n",
    "KEY INFORMATION FOR THIS EXPERIMENT:\n",
    "- Payoff structures may influence their actual decision in specific tasks\n",
    "- Your goal is to maximize your individual points across all tasks\n",
    "\n",
    "Think strategically about:\n",
    "- Risk versus reward given the payoff structures\n",
    "- How the specific payoffs might affect your partner's willingness to collaborate\n",
    "- Whether the guaranteed option is better given the uncertainties involved\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": decision_prompt}\n",
    "        ],\n",
    "    )\n",
    "    decision_text = response.choices[0].message.content.strip()\n",
    "    print(f\"Decision response : {decision_text}\".encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    decision_data = json.loads(decision_text)\n",
    "    \n",
    "    return {\n",
    "        \"choice\": decision_data[\"choice\"],\n",
    "        \"strategy\": decision_data[\"strategy\"],\n",
    "        \"reasoning\": decision_data[\"reasoning\"]\n",
    "    }\n",
    "    \n",
    "def run_second_agent_decision(task, agent2_belief, agent1_belief):\n",
    "    \"\"\"\n",
    "    Running the second agent to make a decision about the task\n",
    "    \"\"\"\n",
    "    \n",
    "    decision_prompt = f\"\"\"\n",
    "    Your task is to make a decision about the given task based on its payoff structures and a given utility value (u_value).\n",
    "\n",
    "    **Your Assessment**: You estimated a {agent2_belief}% chance of selecting a collaborative option.\n",
    "    **Partner's Assessment**: Your partner estimated a {agent1_belief}% chance of selecting a collaborative option.\n",
    "\n",
    "    **Key Facts**:\n",
    "    - Technical failure risk: {int(TECH_FAILURE_RATE*100)} percent\n",
    "    - Threshold for profitable collaboration: {task['u_value']*100:.0f}%\n",
    "\n",
    "    Choose your car design:\n",
    "    - Designs A, B, or C (collaborative): Higher potential but requires cooperation\n",
    "    - Design Y (individual): Guaranteed {task['options']['Y']['guaranteed']} points\n",
    "\n",
    "    What is your decision based on your assessment and partner's assessment?\n",
    "\n",
    "    Respond in JSON format: {{\"choice\": \"A\"/\"B\"/\"C\"/\"Y\", \"strategy\": \"collaborative\"/\"individual\", \"reasoning\": \"your explanation\"}}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "       model=\"gpt-5-nano\",\n",
    "       messages = [{\"role\": \"developer\", \"content\": \"\"\"You are participating in an experiment as a representative of a LEGO car manufacturing company. Here's your situation:\n",
    "\n",
    "CONTEXT:\n",
    "- You represent a LEGO car manufacturing company\n",
    "- Your partner represents another LEGO car manufacturing company\n",
    "- You can build simple LEGO cars alone, or complex ones through collaboration\n",
    "- Collaboration is high risk, high reward with potential for large sunk costs if it fails\n",
    "\n",
    "GAME RULES:\n",
    "- You will complete several tasks to maximize your points\n",
    "- Points are earned individually, not shared with your partner\n",
    "- Points depend on both your decision and your partner's decision\n",
    "- Each task has 4 LEGO car design options\n",
    "- Three options (A, B, C) are collaborative designs requiring partner cooperation\n",
    "- One option (Y) is an individual design with guaranteed points\n",
    "- If both choose collaborative designs (any combination), you earn the upside\n",
    "- If you choose collaborative but partner chooses individual, you get the downside\n",
    "- There's a 5% technical error chance that causes collaboration to fail\n",
    "- You have about 60 seconds to decide\n",
    "\n",
    "KEY INFORMATION FOR THIS EXPERIMENT:\n",
    "- Payoff structures may influence their actual decision in specific tasks\n",
    "- Your goal is to maximize your individual points across all tasks\n",
    "\n",
    "Think strategically about:\n",
    "- Risk versus reward given the payoff structures\n",
    "- How the specific payoffs might affect your partner's willingness to collaborate\n",
    "- Whether the guaranteed option is better given the uncertainties involved\"\"\"},\n",
    "           {\"role\": \"user\", \"content\": decision_prompt}]\n",
    "   )\n",
    "    decision_text = response.choices[0].message.content.strip()\n",
    "    print(f\"Decision response : {decision_text}\".encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    decision_data = json.loads(decision_text)\n",
    "    \n",
    "    return {\n",
    "        \"choice\": decision_data[\"choice\"],\n",
    "        \"strategy\": decision_data[\"strategy\"],\n",
    "        \"reasoning\": decision_data[\"reasoning\"]\n",
    "    }\n",
    "    \n",
    "def safe_print(text):\n",
    "    \"\"\"Helper function to safely print text with Unicode characters\"\"\"\n",
    "    try:\n",
    "        print(text)\n",
    "    except UnicodeEncodeError:\n",
    "        # Fallback: encode with 'replace' to handle problematic characters\n",
    "        print(text.encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    \n",
    "def main():\n",
    "    task = create_task(task_id=1, u_value=0.66)\n",
    "    \n",
    "    print(\"=== Agent 1 Belief ===\")\n",
    "    agent1_belief_data = run_first_agent_belief(task)\n",
    "    agent1_belief = agent1_belief_data[\"belief\"]\n",
    "    agent1_message_to_agent2 = agent1_belief_data[\"message_to_agent_2\"]\n",
    "    \n",
    "    print(\"=== Agent 2 Belief ===\")\n",
    "    agent2_belief_data = run_second_agent_belief(task, agent1_message_to_agent2)\n",
    "    agent2_belief = agent2_belief_data[\"belief\"]\n",
    "    agent2_message_to_agent1 = agent2_belief_data[\"message_to_agent_1\"]\n",
    "    \n",
    "    print(\"=== Agent 1 Decision ===\")\n",
    "    agent1_decision = run_first_agent_decision(task, agent1_belief, agent2_belief, agent2_message_to_agent1)\n",
    "    \n",
    "    print(\"=== Agent 2 Decision ===\")\n",
    "    agent2_decision = run_second_agent_decision(task, agent2_belief, agent1_belief)\n",
    "    \n",
    "    print(\"\\nFinal Decisions:\")\n",
    "    safe_print(f\"Agent 1 chose {agent1_decision['choice']} ({agent1_decision['strategy']}) - Reasoning: {agent1_decision['reasoning']}\")\n",
    "    safe_print(f\"Agent 2 chose {agent2_decision['choice']} ({agent2_decision['strategy']}) - Reasoning: {agent2_decision['reasoning']}\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe514725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SINGLE AGENT EXPERIMENT — CONTROL (no channel)\n",
      "==================================================\n",
      "\n",
      "Task 1 (u hidden; internal u=0.55)\n",
      "Belief response: {\"belief\": 75}\n",
      "Decision response: {\"strategy\": \"collaborate\", \"option\": \"B\"}\n",
      "Summary: belief=75%, strategy=collaborate, option=B, consistent=True\n",
      "\n",
      "Task 2 (u hidden; internal u=0.70)\n",
      "Belief response: {\"belief\": 75}\n",
      "Decision response: {\"strategy\": \"collaborate\", \"option\": \"B\"}\n",
      "Summary: belief=75%, strategy=collaborate, option=B, consistent=True\n",
      "\n",
      "Task 3 (u hidden; internal u=0.85)\n",
      "Belief response: {\"belief\": 75}\n",
      "Decision response: {\"strategy\": \"collaborate\", \"option\": \"B\"}\n",
      "Summary: belief=75%, strategy=collaborate, option=B, consistent=False\n",
      "\n",
      "Saved: results_20250919_113046.json\n",
      "\n",
      "==================================================\n",
      "EXPERIMENT COMPLETE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# ========== Task Factory (keep for now; we'll swap in generator later) ==========\n",
    "def create_task(task_id=1, difficulty=0.70):\n",
    "    \"\"\"\n",
    "    Create a task with a given difficulty level.\n",
    "    NOTE: This is a placeholder. In replication, replace with a generator derived from (u, G) and support asymmetry.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"task_id\": task_id,\n",
    "        \"difficulty\": difficulty,     # alias of u_value for now\n",
    "        \"u_value\": difficulty,        # minimum belief needed to collaborate (NOT shown in control)\n",
    "        \"options\": {\n",
    "            \"A\": {\"upside\": 111, \"downside\": -90},\n",
    "            \"B\": {\"upside\":  92, \"downside\": -45},\n",
    "            \"C\": {\"upside\":  77, \"downside\": -15},\n",
    "            \"Y\": {\"guaranteed\": 50}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ========== Prompts ==========\n",
    "SYSTEM_BRIEFING = (\n",
    "    \"You are a participant in a paired decision-making game.\\n\"\n",
    "    \"Follow these rules exactly:\\n\"\n",
    "    \"• You are paired with one partner.\\n\"\n",
    "    \"• You will complete several tasks; you can earn or lose points. Maximize your own total points.\\n\"\n",
    "    \"• Your points depend on both your decision and your partner’s decision.\\n\"\n",
    "    \"Scenario:\\n\"\n",
    "    \"You and your partner each lead a startup designing new mobile apps. Option Y is a simple solo app (guaranteed 50 points). \"\n",
    "    \"Options A, B, C are more ambitious collaborative apps: higher potential payoffs if both collaborate; losses if you collaborate while your partner does not. Collaboration is high risk, high reward.\\n\"\n",
    "    \"Game rules:\\n\"\n",
    "    \"• Each task shows three collaborative options (A,B,C) and one independent option (Y).\\n\"\n",
    "    \"• If both choose collaborative options, collaboration succeeds (even if you choose different letters).\\n\"\n",
    "    \"• If one collaborates and the other does not, the collaborator takes the downside loss.\\n\"\n",
    "    \"• Rarely, a technical error (~5%) may cause collaboration to fail.\\n\"\n",
    "    \"• You may exchange a short message, but you do not see your partner’s payoff table.\\n\"\n",
    "    \"Output rules:\\n\"\n",
    "    \"• Always respond in valid JSON only (no extra text). Use exactly the fields requested.\\n\"\n",
    "    \"• Think privately if useful, but output only the requested JSON.\"\n",
    ")\n",
    "\n",
    "def make_belief_prompt(task):\n",
    "    o = task[\"options\"]\n",
    "    return (\n",
    "        \"PRIVATE PAYOFFS FOR YOU:\\n\"\n",
    "        f\"Option A: Success = {o['A']['upside']}, Failure = {o['A']['downside']}\\n\"\n",
    "        f\"Option B: Success = {o['B']['upside']}, Failure = {o['B']['downside']}\\n\"\n",
    "        f\"Option C: Success = {o['C']['upside']}, Failure = {o['C']['downside']}\\n\"\n",
    "        f\"Option Y: Guaranteed = {o['Y']['guaranteed']}\\n\\n\"\n",
    "        \"Your partner’s payoff table may be similar or different from yours. You cannot see their numbers.\\n\\n\"\n",
    "        \"Task: Report your belief (0-100) that collaboration will succeed (i.e., both partners choose to collaborate) on this task.\\n\\n\"\n",
    "        'Respond ONLY in JSON:\\n{\"belief\": <integer 0..100>}'\n",
    "    )\n",
    "\n",
    "def make_decision_prompt_control(task, belief_int):\n",
    "    o = task[\"options\"]\n",
    "    return (\n",
    "        \"PRIVATE PAYOFFS FOR YOU:\\n\"\n",
    "        f\"Option A: Success = {o['A']['upside']}, Failure = {o['A']['downside']}\\n\"\n",
    "        f\"Option B: Success = {o['B']['upside']}, Failure = {o['B']['downside']}\\n\"\n",
    "        f\"Option C: Success = {o['C']['upside']}, Failure = {o['C']['downside']}\\n\"\n",
    "        f\"Option Y: Guaranteed = {o['Y']['guaranteed']}\\n\\n\"\n",
    "        f\"You previously reported: {{\\\"belief\\\": {belief_int}}}\\n\\n\"\n",
    "        'Respond ONLY in JSON:\\n{\"strategy\": \"collaborate\"|\"individual\", \"option\": \"A\"|\"B\"|\"C\"|\"Y\"}'\n",
    "    )\n",
    "\n",
    "# ========== Helpers ==========\n",
    "def call_json(model, system_prompt, user_prompt, temperature=0.1):\n",
    "    \"\"\"Call the model and return raw text (expected to be JSON).\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def try_parse_json(text):\n",
    "    try:\n",
    "        return json.loads(text), None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def clamp_belief(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        return None\n",
    "    return max(0, min(100, x))\n",
    "\n",
    "def validate_decision(obj):\n",
    "    if not isinstance(obj, dict): return False, \"not a dict\"\n",
    "    strat = obj.get(\"strategy\")\n",
    "    opt   = obj.get(\"option\")\n",
    "    if strat not in (\"collaborate\", \"individual\"):\n",
    "        return False, \"invalid strategy\"\n",
    "    if opt not in (\"A\", \"B\", \"C\", \"Y\"):\n",
    "        return False, \"invalid option\"\n",
    "    # coherence: Y iff individual; A/B/C iff collaborate\n",
    "    if strat == \"individual\" and opt != \"Y\":\n",
    "        return False, \"individual must pick Y\"\n",
    "    if strat == \"collaborate\" and opt not in (\"A\",\"B\",\"C\"):\n",
    "        return False, \"collaborate must pick A/B/C\"\n",
    "    return True, \"\"\n",
    "\n",
    "# ========== Single-Agent Control Flow (no u shown) ==========\n",
    "def run_single_agent_control(task, model=\"gpt-4-0125-preview\", temperature=0.1, max_retries=1):\n",
    "    \"\"\"\n",
    "    Single-agent CONTROL condition (no channel; u is NOT shown).\n",
    "    Phase 1: belief JSON\n",
    "    Phase 2: decision JSON (strategy/option), using same payoff table.\n",
    "    \"\"\"\n",
    "    # --- Phase 1: belief ---\n",
    "    belief_prompt = make_belief_prompt(task)\n",
    "    raw_belief = call_json(model, SYSTEM_BRIEFING, belief_prompt, temperature)\n",
    "    print(f\"Belief response: {raw_belief}\".encode(sys.stdout.encoding or \"utf-8\", errors='replace').decode(sys.stdout.encoding or \"utf-8\"))\n",
    "\n",
    "    data, err = try_parse_json(raw_belief)\n",
    "    belief_int = None\n",
    "    if not err and isinstance(data, dict) and \"belief\" in data:\n",
    "        belief_int = clamp_belief(data[\"belief\"])\n",
    "\n",
    "    # one reprompt if needed\n",
    "    retries = 0\n",
    "    while (belief_int is None) and retries < max_retries:\n",
    "        reprompt = 'Please respond ONLY in JSON: {\"belief\": <integer 0..100>}'\n",
    "        raw_belief = call_json(model, SYSTEM_BRIEFING, reprompt, temperature)\n",
    "        print(f\"Belief reprompt: {raw_belief}\")\n",
    "        data, err = try_parse_json(raw_belief)\n",
    "        if not err and isinstance(data, dict) and \"belief\" in data:\n",
    "            belief_int = clamp_belief(data[\"belief\"])\n",
    "        retries += 1\n",
    "\n",
    "    if belief_int is None:\n",
    "        print(\"Failed to parse belief; defaulting to 50.\")\n",
    "        belief_int = 50\n",
    "\n",
    "    # --- Phase 2: decision (control; still no u) ---\n",
    "    decision_prompt = make_decision_prompt_control(task, belief_int)\n",
    "    raw_decision = call_json(model, SYSTEM_BRIEFING, decision_prompt, temperature)\n",
    "    print(f\"Decision response: {raw_decision}\".encode(sys.stdout.encoding or \"utf-8\", errors='replace').decode(sys.stdout.encoding or \"utf-8\"))\n",
    "\n",
    "    decision_obj, derr = try_parse_json(raw_decision)\n",
    "    ok, why = validate_decision(decision_obj) if not derr else (False, derr)\n",
    "\n",
    "    # one reprompt if invalid\n",
    "    retries = 0\n",
    "    while (not ok) and retries < max_retries:\n",
    "        reprompt = 'Respond ONLY in JSON: {\"strategy\": \"collaborate\"|\"individual\", \"option\": \"A\"|\"B\"|\"C\"|\"Y\"}'\n",
    "        raw_decision = call_json(model, SYSTEM_BRIEFING, reprompt, temperature)\n",
    "        print(f\"Decision reprompt: {raw_decision}\")\n",
    "        decision_obj, derr = try_parse_json(raw_decision)\n",
    "        ok, why = validate_decision(decision_obj) if not derr else (False, derr)\n",
    "        retries += 1\n",
    "\n",
    "    if not ok:\n",
    "        print(f\"Failed to parse decision ({why}); defaulting to individual Y.\")\n",
    "        decision_obj = {\"strategy\": \"individual\", \"option\": \"Y\"}\n",
    "\n",
    "    # --- consistency flag (EV-threshold heuristic for sanity, not shown to agent) ---\n",
    "    # NOTE: This is only for a quick internal check; it is not used in prompts.\n",
    "    consistent = (belief_int > int(task[\"u_value\"] * 100)) == (decision_obj[\"strategy\"] == \"collaborate\")\n",
    "\n",
    "    result = {\n",
    "        \"task_id\": task[\"task_id\"],\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"condition\": \"control\",\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"belief\": belief_int,\n",
    "        \"decision\": decision_obj,\n",
    "        \"u_value\": task[\"u_value\"],\n",
    "        \"raw_belief_msg\": raw_belief,\n",
    "        \"raw_decision_msg\": raw_decision,\n",
    "        \"consistent\": consistent\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# ========== Runner ==========\n",
    "def main():\n",
    "    print(\"=\"*50)\n",
    "    print(\"SINGLE AGENT EXPERIMENT — CONTROL (no channel)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    tasks = [\n",
    "        create_task(1, 0.55),\n",
    "        create_task(2, 0.70),\n",
    "        create_task(3, 0.85),\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for task in tasks:\n",
    "        print(f\"\\nTask {task['task_id']} (u hidden; internal u={task['u_value']:.2f})\")\n",
    "        result = run_single_agent_control(task)\n",
    "        results.append(result)\n",
    "        print(f\"Summary: belief={result['belief']}%, strategy={result['decision']['strategy']}, option={result['decision']['option']}, consistent={result['consistent']}\")\n",
    "\n",
    "    outpath = f\"results_{datetime.now():%Y%m%d_%H%M%S}.json\"\n",
    "    with open(outpath, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(\"\\nSaved:\", outpath)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPERIMENT COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1524d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "\"\"\"\"\"\n",
    "Single Agent Experiment\n",
    "\"\"\"\n",
    "\n",
    "# Openrouter \n",
    "# EV = prob * upside - prob *downside\n",
    "def create_task(task_id = 1, difficulty = 0.7):\n",
    "    \"\"\"\n",
    "    Create a task with a given difficulty level.\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"task_id\": task_id,\n",
    "        \"difficulty\": difficulty,\n",
    "        \"options\": {\n",
    "            \"A\": {\"upside\": 111, \"downside\": -90},\n",
    "            \"B\": {\"upside\": 92, \"downside\": -45},\n",
    "            \"C\": {\"upside\": 77, \"downside\": -15},\n",
    "            \"Y\": {\"guaranteed\": 50}\n",
    "        },\n",
    "        \"u_value\": difficulty  # minimum belief needed to collaborate\n",
    "    }\n",
    "\n",
    "def run_single_agent(task, model=\"gpt-4-0125-preview\", temperature=0.1):\n",
    "    \"\"\"\n",
    "    Run a single task with one agent\n",
    "    Args:\n",
    "        task: The task dictionary\n",
    "        model: The OpenAI model to use (default: gpt-4-0125-preview)\n",
    "        temperature: Controls randomness (0-2). Lower = more deterministic (default: 0.7)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Phase 1 : Get the belief prompt\n",
    "    \n",
    "    belief_prompt = f\"\"\"You are evaluating these options:\n",
    "\n",
    "Options A, B, C require collaboration:\n",
    "- A: Success={task['options']['A']['upside']} points, Failure={task['options']['A']['downside']} points\n",
    "- B: Success={task['options']['B']['upside']} points, Failure={task['options']['B']['downside']} points  \n",
    "- C: Success={task['options']['C']['upside']} points, Failure={task['options']['C']['downside']} points\n",
    "\n",
    "Options A, B, C require cooperation with a partner to succeed. The downside of failure can impact your score significantly.\n",
    "\n",
    "Option Y is independent and guaranteed.\n",
    "Option Y is guaranteed: {task['options']['Y']['guaranteed']} points\n",
    "\n",
    "Before deciding, consider the following:\n",
    "- What are the chances of your partner cooperating?\n",
    "- If you believe the chances are high (above {task['u_value']*100:.2f}% confidence), you should consider collaborating.\n",
    "- If you're uncertain, the guaranteed points from Option Y might be safer, but will you lose out on potentially larger rewards from collaboration?\n",
    "\n",
    "What's your belief (0-100) that collaboration will succeed, considering both the rewards and risks?\n",
    "\n",
    "Respond in JSON: {{\"belief\": NUMBER, \"reasoning\": \"brief explanation based on risk vs reward\"}}\"\"\"\n",
    "\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"\"\"You are an undergraduate student participating in an experiment focused on collaborative decision-making. Your task is to evaluate the given options based on the context provided. Please consider both the potential rewards and the risks of each option before making your decision.\n",
    "\n",
    "In this experiment:\n",
    "- Options A, B, and C require collaboration with a partner. Each collaboration option has potential rewards for success and consequences for failure.\n",
    "- Option Y is an independent option with a guaranteed reward but no risk of failure.\n",
    "- Your belief about how likely collaboration will succeed plays a key role in your decision. Think about whether the rewards of collaboration outweigh the risks.\n",
    "- Please **reason through** the decision-making process like you would in real life, considering both your expectations for collaboration and the potential outcomes of working together versus acting alone.\n",
    "\n",
    "For each task:\n",
    "- Evaluate the potential rewards and risks of collaboration vs. independent action.\n",
    "- Reflect on whether the probability of success (your belief) is high enough to justify collaboration or if the guaranteed option (Y) is safer.\n",
    "\n",
    "Your response should focus on both reasoning through your belief and analyzing whether collaboration is the best option, considering the trade-offs involved.\"\"\" \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": belief_prompt\n",
    "        }],\n",
    "        temperature=temperature  # Add temperature control\n",
    "    )\n",
    "    \n",
    "    belief_text = response.choices[0].message.content\n",
    "    print(f\"Belief response : {belief_text}\".encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    \n",
    "    try:\n",
    "        belief_data = json.loads(belief_text)\n",
    "        belief = belief_data[\"belief\"]\n",
    "    except:\n",
    "        print(\"Failed to parse belief, using default\")\n",
    "        belief = 50\n",
    "        \n",
    "        # Phase 2 : Make the decision prompt\n",
    "    decision_prompt = f\"\"\"\n",
    "Based on the options, make your final choice.\n",
    "\n",
    "- The minimum belief needed to collaborate is {task['u_value']*100:.2f}%.\n",
    "- You reported a belief of {belief}%.\n",
    "\n",
    "Before making your decision, consider the following:\n",
    "- If you collaborate (A, B, or C), you have a chance to earn a larger reward, but there is a risk of failure. \n",
    "- If you choose the independent option (Y), you are guaranteed {task['options']['Y']['guaranteed']} points with no risk of failure, but the payoff may be smaller.\n",
    "\n",
    "Given your belief of {belief}%, do you think that collaboration with your partner will yield a better payoff than acting independently? Consider:\n",
    "- If your belief is higher than {task['u_value']*100:.2f}%, it may be worth collaborating.\n",
    "- If your belief is lower, you might prefer to take the guaranteed points from option Y.\n",
    "\n",
    "Make your decision:\n",
    "- Choose collaboration (A, B, or C) if you believe the collaboration will lead to better outcomes.\n",
    "- Choose independence (Y) if the guaranteed points seem like a safer option given the risk.\n",
    "\n",
    "Respond in JSON: {{\"choice\": \"LETTER\", \"strategy\": \"collaborative\" or \"individual\", \"reasoning\": \"Why you made this choice based on your belief and the trade-offs between collaboration and independence.\"}}\n",
    "\"\"\"\n",
    "            \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"\"\"You are an undergraduate student participating in an experiment focused on collaborative decision-making. Your task is to evaluate the given options based on the context provided. Please consider both the potential rewards and the risks of each option before making your decision.\n",
    "\n",
    "In this experiment:\n",
    "- Options A, B, and C require collaboration with a partner. Each collaboration option has potential rewards for success and consequences for failure.\n",
    "- Option Y is an independent option with a guaranteed reward but no risk of failure.\n",
    "- Your belief about how likely collaboration will succeed plays a key role in your decision. Think about whether the rewards of collaboration outweigh the risks.\n",
    "- Please **reason through** the decision-making process like you would in real life, considering both your expectations for collaboration and the potential outcomes of working together versus acting alone.\n",
    "\n",
    "For each task:\n",
    "- Evaluate the potential rewards and risks of collaboration vs. independent action.\n",
    "- Reflect on whether the probability of success (your belief) is high enough to justify collaboration or if the guaranteed option (Y) is safer.\n",
    "\n",
    "Your response should focus on both reasoning through your belief and analyzing whether collaboration is the best option, considering the trade-offs involved.\"\"\" \n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": decision_prompt\n",
    "        }],\n",
    "        temperature=temperature  # Add temperature control\n",
    "    )\n",
    "    decision_text = response.choices[0].message.content\n",
    "    print(f\"Decision response : {decision_text}\".encode(sys.stdout.encoding, errors='replace').decode(sys.stdout.encoding))\n",
    "    try:\n",
    "        decision_data = json.loads(decision_text)\n",
    "    except:\n",
    "        print(\"Failed to parse decision\")\n",
    "        decision_data = {\"choice\": \"Y\", \"strategy\": \"individual\"}\n",
    "    \n",
    "    result = {\n",
    "        \"task_id\": task[\"task_id\"],\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"belief\": belief,\n",
    "        \"decision\": decision_data,\n",
    "        \"u_value\": task[\"u_value\"],\n",
    "        \"consistent\": (belief > task[\"u_value\"]*100) == (decision_data.get(\"strategy\") == \"collaborative\")\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run experiment\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"SINGLE AGENT EXPERIMENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create a few test tasks\n",
    "    tasks = [\n",
    "        create_task(1, 0.55),  # Easy (need 55% belief)\n",
    "        create_task(2, 0.70),  # Medium (need 70% belief)\n",
    "        create_task(3, 0.85),  # Hard (need 85% belief)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for task in tasks:\n",
    "        print(f\"\\nTask {task['task_id']} (u={task['u_value']}):\")\n",
    "        result = run_single_agent(task)\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"Summary: Belief={result['belief']}%, Choice={result['decision']['choice']}, Consistent={result['consistent']}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(f\"results_{datetime.now():%Y%m%d_%H%M%S}.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXPERIMENT COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    \n",
    "#Change the system prompt (default prompt)\n",
    "#change the model\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e4d33",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1901b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ffd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
