# Trust-Based vs Bayesian Agent Comparison Study

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

A comprehensive computational study comparing trust-based and Bayesian learning agents in repeated stag hunt games, with extensive sensitivity analysis of agent parameters.

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Findings](#key-findings)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Detailed Analysis](#detailed-analysis)
- [Sensitivity Analysis](#sensitivity-analysis)
- [Results Organization](#results-organization)
- [Installation](#installation)
- [Usage](#usage)
- [Methodology](#methodology)
- [Authors](#authors)

## ðŸŽ¯ Overview

This study implements and compares two types of learning agents in repeated stag hunt games:

### ðŸ¤ Trust-Based Agent (Focal Agent)
- **Dual-state model**: Signal (x) and Trust (t) with asymmetric penalties
- **Loss aversion**: Different weights for betrayal vs. surprise
- **Adaptive learning**: Updates beliefs based on trust dynamics
- **Stochastic decisions**: Logit choice with inverse temperature parameter

### ðŸŽ² Bayesian Agent
- **Conjugate prior**: Beta-Bernoulli updating
- **Probabilistic reasoning**: Updates beliefs using Bayes' theorem
- **Memory-less**: Each observation weighted equally

## ðŸ† Key Findings

### Agent Performance Comparison
- **Trust-based agent excels** against non-stationary partners (SingleCycle, GradualDeterioration, ExpectationViolation)
- **Bayesian agent performs better** against stationary partners (TitForTat, GrimTrigger)
- **Trust-based agent shows advantage** with increased interaction rounds

### Key Performance Metrics
| Metric | Definition | Interpretation |
|--------|------------|----------------|
| **Mutual Cooperation Rate** | Proportion of rounds where both agent and partner cooperate | Higher is better (successful collaboration) |
| **Betrayal Rate** | Proportion of rounds where agent cooperates but partner defects | Lower is better (agent's vulnerability to exploitation) |
| **Total Payoff** | Cumulative reward over all rounds | Higher is better (overall performance) |

### Parameter Sensitivity Results
Complete sensitivity analysis of **9 parameters** across 5 partner types:
- **eta** (learning rate): [0.1, 0.3, 0.5, 0.7, 0.9]
- **memory_discount**: [0.5, 0.7, 0.8, 0.9, 0.95]
- **trust_discount**: [0.5, 0.7, 0.8, 0.9, 0.95]
- **trust_smoothing**: [0.1, 0.2, 0.3, 0.5, 0.7]
- **loss_aversion**: [1.0, 1.5, 2.0, 3.0, 5.0]
- **lambda_surprise**: [0.0, 0.25, 0.5, 0.75, 1.0]
- **inverse_temperature**: [0.5, 2.0, 5.0, 10.0]
- **initial_x** (1 - normalized deviation loss u-i): [0.2, 0.33, 0.5, 0.9]
- **t_init** (initial trust): [0.1, 0.5, 1.0, 5.0]

### Advanced Analysis Features
- **Parameter Effect Size Analysis**: Quantifies which parameters actually matter (HIGH/MEDIUM/LOW impact classification)
- **Interaction Analysis**: 15-heatmap visualization of `initial_x Ã— t_init` interactions across all partners and metrics
- **Optimal Parameter Recommendations**: Partner-specific parameter tuning suggestions

## ðŸ“ Project Structure

```
trust-bayesian-agent-comparison/
â”œâ”€â”€ ðŸ““ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ Parameter_Sensitivity_Analysis.ipynb    # â­ Main sensitivity analysis
â”‚   â”œâ”€â”€ Trust_Agent_Excellence_Analysis.ipynb   # Winning partners analysis
â”‚   â”œâ”€â”€ Rounds_Analysis.ipynb                   # Rounds effect analysis
â”‚   â”œâ”€â”€ Trust_updated_focal_stoch_Betray.ipynb  # Original implementation
â”‚   â””â”€â”€ 00_quick_start_refactored.ipynb         # Tutorial
â”œâ”€â”€ ðŸ“œ scripts/                      # Analysis scripts
â”‚   â”œâ”€â”€ run_all_sensitivity.py       # â­ Run all 7 parameters
â”‚   â”œâ”€â”€ run_inverse_temp_sensitivity.py        # Quick inverse temp test
â”‚   â”œâ”€â”€ run_demo.py                  # Fast demo (10 runs)
â”‚   â”œâ”€â”€ run_full_study.py            # Production study (300 runs)
â”‚   â”œâ”€â”€ run_rounds_analysis.py       # Rounds effect analysis
â”‚   â””â”€â”€ view_all_tables.py           # Results viewer
â”œâ”€â”€ ðŸ“Š results/                      # Analysis results
â”‚   â”œâ”€â”€ experiments/                 # Individual experiment CSVs
â”‚   â”œâ”€â”€ summaries/                   # Summary comparison tables
â”‚   â”œâ”€â”€ sensitivity_*/               # Parameter sensitivity results
â”‚   â”œâ”€â”€ sensitivity_interaction_x_t/ # Signal Ã— trust interaction results
â”‚   â”œâ”€â”€ figures/                     # Generated visualizations
â”‚   â”‚   â”œâ”€â”€ interaction_x_t_heatmaps.png    # â­ New: 15-heatmap interaction analysis
â”‚   â”‚   â”œâ”€â”€ parameter_effect_sizes.png      # â­ New: Effect size heatmaps
â”‚   â”‚   â”œâ”€â”€ focal_expected_p_evolution.png
â”‚   â”‚   â”œâ”€â”€ focal_signal_evolution.png
â”‚   â”‚   â”œâ”€â”€ focal_trust_evolution.png
â”‚   â”‚   â”œâ”€â”€ focal_final_distributions.png
â”‚   â”‚   â”œâ”€â”€ belief_trajectories.png
â”‚   â”‚   â”œâ”€â”€ cooperation_rates.png
â”‚   â”‚   â””â”€â”€ payoff_advantage.png
â”‚   â””â”€â”€ rounds_analysis/             # Rounds effect analysis
â”œâ”€â”€ ðŸ—ï¸ trust_bayesian_agent_comparison/  # Source code
â”‚   â”œâ”€â”€ agents/                      # Agent implementations
â”‚   â”œâ”€â”€ partners/                    # Partner strategy implementations
â”‚   â”œâ”€â”€ simulation/                  # Game simulation engine
â”‚   â”œâ”€â”€ analysis/                    # Analysis and metrics
â”‚   â””â”€â”€ visualization/               # Plotting utilities
â”œâ”€â”€ ðŸ“š Documentation
â”‚   â”œâ”€â”€ ANALYSIS_GUIDE.md            # How to interpret results
â”‚   â”œâ”€â”€ ROUNDS_ANALYSIS_README.md    # Rounds analysis guide
â”‚   â””â”€â”€ CLEANUP_SUMMARY.txt          # Project cleanup history
â””â”€â”€ âš™ï¸ Configuration
    â”œâ”€â”€ pyproject.toml               # Project dependencies
    â”œâ”€â”€ poetry.lock                  # Locked dependencies
    â””â”€â”€ .gitignore                   # Git ignore rules
```

## ðŸš€ Quick Start

### Option 1: Demo Mode (Fast, 5 minutes)
```bash
# Run quick demo with 5 partners, 10 Monte Carlo runs each
python scripts/run_demo.py
```

### Option 2: Full Study (Complete, 30-60 minutes)
```bash
# Run comprehensive study with 13 partners, 300 Monte Carlo runs each
python scripts/run_full_study.py
```

### Option 3: Sensitivity Analysis (Complete parameter sweep)
```bash
# Run sensitivity analysis for all 7 parameters
python scripts/run_all_sensitivity.py
```

## ðŸ“Š Detailed Analysis

### Monte Carlo Comparison
- **300 runs** per agent-partner combination
- **13 partner types**: Fixed, reactive, adaptive, and cheating strategies
- **3 metrics**: Mutual cooperation rate, betrayal rate, total payoff

### Rounds Effect Analysis
- **7 round counts**: 10, 50, 70, 100, 200, 300, 500, 1000
- **3 partner categories**: Belief-driven, Fixed, Reactive
- **Performance tracking**: Adaptation speed, convergence stability

### Parameter Sensitivity Analysis
- **7 parameters** varied independently
- **5 representative partners**: SingleCycle, GradualDeterioration, ExpectationViolation, StrategicCheater, TitForTat
- **Optimal parameter identification** for each metric and partner

## ðŸ”¬ Sensitivity Analysis

### Parameters Analyzed

| Parameter | Description | Range | Default |
|-----------|-------------|-------|---------|
| **eta** | Learning rate for signal updates | [0.1, 0.9] | 0.3 |
| **memory_discount** | Recency weighting for signals | [0.5, 0.95] | 0.9 |
| **trust_discount** | Recency weighting for trust | [0.5, 0.95] | 0.8 |
| **trust_smoothing** | Trust update smoothing factor | [0.1, 0.7] | 0.2 |
| **loss_aversion** | Betrayal penalty multiplier (Î») | [1.0, 5.0] | 2.0 |
| **lambda_surprise** | Surprise penalty multiplier (Î¼) | [0.0, 1.0] | 0.5 |
| **inverse_temperature** | Exploration-exploitation balance | [0.5, 10.0] | 2.0 |
| **initial_x** | Initial signal (normalized deviation loss u-i) | [0.2, 0.33, 0.5, 0.9] | 0.33 |
| **t_init** | Initial trust/confidence | [0.1, 5.0] | 1.0 |

### Advanced Analysis Features

#### Parameter Effect Size Analysis
- **Effect Size Calculation**: `(max - min) / mean Ã— 100%` for each parameter Ã— partner Ã— metric
- **Impact Classification**: 
  - ðŸ”´ **HIGH IMPACT** (>10% effect): Core parameters driving behavior
  - ðŸŸ¡ **MEDIUM IMPACT** (3-10% effect): Worth considering for optimization
  - ðŸŸ¢ **LOW IMPACT** (<3% effect): Candidates for fixed defaults
- **Model Simplification Guidance**: Identifies parameters that can be safely fixed

#### Interaction Analysis
- **15-Heatmap Visualization**: `initial_x Ã— t_init` interactions across 5 partners Ã— 3 metrics
- **Signal Ã— Trust Dynamics**: Shows how prior beliefs and confidence interact
- **Partner-Specific Patterns**: Reveals context-dependent parameter effects

### Key Insights
- **Trust-based agent** shows robust performance across parameter ranges
- **Parameter interactions** exist but single-parameter optimization provides good baselines
- **Partner-specific optimization** often yields better results than universal settings
- **Effect size analysis** reveals which parameters truly matter for model behavior

## ðŸ“ Results Organization

```
results/
â”œâ”€â”€ experiments/           # Raw experiment data (26 CSV files)
â”‚   â”œâ”€â”€ Adaptive_agent1.csv
â”‚   â”œâ”€â”€ SingleCycle_agent2.csv
â”‚   â””â”€â”€ ... (all agent-partner combinations)
â”œâ”€â”€ summaries/             # Aggregated comparison tables
â”‚   â”œâ”€â”€ mutual_cooperation_comparison.csv
â”‚   â”œâ”€â”€ total_payoff_comparison.csv
â”‚   â””â”€â”€ summary_statistics.csv
â”œâ”€â”€ sensitivity_*/         # Parameter sensitivity results
â”‚   â”œâ”€â”€ eta/ExpectationViolation_results.csv
â”‚   â”œâ”€â”€ memory_discount/SingleCycle_results.csv
â”‚   â””â”€â”€ ... (all parameter-partner combinations)
â”œâ”€â”€ figures/               # Generated visualizations
â”‚   â”œâ”€â”€ focal_signal_evolution.png
â”‚   â”œâ”€â”€ payoff_comparison.png
â”‚   â””â”€â”€ rounds_analysis/
â””â”€â”€ rounds_analysis/       # Rounds effect analysis
    â”œâ”€â”€ all_rounds_analysis.csv
    â””â”€â”€ belief_driven_results.csv
```

## ðŸ’» Installation

### Prerequisites
- Python 3.8+
- Poetry (recommended) or pip

### Using Poetry (Recommended)
```bash
# Clone repository
git clone https://github.com/Mobinzarreh/trust-bayesian-agent-comparison.git
cd trust-bayesian-agent-comparison

# Install dependencies
poetry install

# Activate virtual environment
poetry shell
```

### Using pip
```bash
# Install dependencies
pip install numpy pandas matplotlib seaborn scipy joblib
```

## ðŸŽ® Usage

### Running Analyses

```bash
# Quick demo (5 minutes)
python scripts/run_demo.py

# Full production study (30-60 minutes)
python scripts/run_full_study.py

# Sensitivity analysis for all parameters (15-20 minutes)
python scripts/run_all_sensitivity.py

# Analyze effect of interaction rounds (10-15 minutes)
python scripts/run_rounds_analysis.py

# View all comparison tables
python scripts/view_all_tables.py
```

### Jupyter Notebooks

```bash
# Launch Jupyter
jupyter notebook

# Open main notebooks:
# - notebooks/Parameter_Sensitivity_Analysis.ipynb (â­ Main analysis)
# - notebooks/Trust_Agent_Excellence_Analysis.ipynb
# - notebooks/Rounds_Analysis.ipynb
```

## ðŸ”¬ Methodology

### Game Setup
- **Stag Hunt Game**: Payoff matrix with coordination incentives
- **Repeated interactions**: 100 rounds per simulation
- **Stochastic decisions**: Logit choice with inverse temperature
- **Monte Carlo analysis**: Multiple random seeds for robustness

### Agent Models

#### Trust-Based Agent
```
Signal Update: x â† Î· * x + (1-Î·) * observed_action
Trust Update: t â† trust_discount * t + trust_smoothing * (signal - t)
Decision: P(cooperate) = 1 / (1 + exp(-(expected_utility * inverse_temperature)))
```

#### Bayesian Agent
```
Prior: Beta(Î±, Î²)
Likelihood: Bernoulli(p)
Posterior: Beta(Î± + successes, Î² + failures)
Decision: P(cooperate) = 1 / (1 + exp(-(expected_p * inverse_temperature)))
```

### Partner Strategies
- **Fixed**: AlwaysCooperate, AlwaysDefect, Random
- **Reactive**: TitForTat, GrimTrigger, Pavlov
- **Adaptive**: Belief-driven partners that learn opponent behavior
- **Cheating**: SingleCycle, StrategicCheater, PeriodicCheater

## ðŸ“ˆ Results Summary

### Performance Comparison
```
Mutual Cooperation Rate:
Trust-based: 0.72 Â± 0.15    Bayesian: 0.68 Â± 0.18

Betrayal Rate:
Trust-based: 0.18 Â± 0.12    Bayesian: 0.22 Â± 0.14

Total Payoff:
Trust-based: 285 Â± 45       Bayesian: 275 Â± 52
```

### Optimal Parameters (Example for SingleCycle partner)
- **eta**: 0.7 (best for mutual cooperation)
- **memory_discount**: 0.95 (best for payoff)
- **inverse_temperature**: 2.0 (balanced performance)

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- Research advisor for guidance on trust modeling
- Open-source community for scientific computing tools
- Contributors to the stag hunt game theory literature

## ðŸ“§ Contact

**Mobin Zarreh**
- GitHub: [@Mobinzarreh](https://github.com/Mobinzarreh)
- Email: [mobin.zarreh@asu.edu]

---

**â­ Star this repository** if you find it useful for your research on trust modeling, agent based modeling simulation, or game theory!
## License

TBD
